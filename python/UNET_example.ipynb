{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Just an exercize\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torchvision.transforms.functional as TF\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class DoubleConv(nn.Module):\r\n",
    "    def __init__(self, in_channels, out_channels):\r\n",
    "        super(DoubleConv, self).__init__()\r\n",
    "        self.conv = nn.Sequential(\r\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\r\n",
    "            nn.BatchNorm2d(out_channels),\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\r\n",
    "            nn.BatchNorm2d(out_channels),\r\n",
    "            nn.ReLU(inplace=True)\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        return self.conv(x)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class UNET(nn.Module):\r\n",
    "    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\r\n",
    "        super(UNET, self).__init__()\r\n",
    "        self.ups = nn.ModuleList()\r\n",
    "        self.downs = nn.ModuleList()\r\n",
    "        self.pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\r\n",
    "\r\n",
    "        for feature in features:\r\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\r\n",
    "            in_channels = feature\r\n",
    "\r\n",
    "        for feature in reversed(features):\r\n",
    "            self.ups.append(nn.ConvTranspose2d(\r\n",
    "                feature*2, feature, kernel_size=2, stride=2))\r\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\r\n",
    "\r\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\r\n",
    "        self.finalConv = nn.Conv2d(features[0], out_channels, kernel_size=1)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        skip_conn = []\r\n",
    "        for down in self.downs:\r\n",
    "            x = down(x)\r\n",
    "            skip_conn.append(x)\r\n",
    "            x = self.pool2d(x)\r\n",
    "\r\n",
    "        x = self.bottleneck(x)\r\n",
    "        skip_conn = skip_conn[::-1]\r\n",
    "\r\n",
    "        for idx in range(0, len(self.ups), 2):\r\n",
    "            x = self.ups[idx](x)\r\n",
    "            skip_co = skip_conn[idx//2]\r\n",
    "\r\n",
    "            if x.shape != skip_co.shape:\r\n",
    "                x = TF.resize(x, size=skip_co.shape[2:])\r\n",
    "\r\n",
    "            concat_skip = torch.cat((skip_co, x), dim=1)\r\n",
    "            x = self.ups[idx+1](concat_skip)\r\n",
    "\r\n",
    "        return self.finalConv(x)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "x = torch.randn((3, 1, 16, 16))\r\n",
    "model = UNET(in_channels=1, out_channels=1)\r\n",
    "preds = model(x)\r\n",
    "# print('prediction: {}'.format(preds))\r\n",
    "# print(\"original: {}\".format(x))\r\n",
    "\r\n",
    "assert preds.shape == x.shape\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\david\\miniconda3\\envs\\tesi\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import os\r\n",
    "from PIL import Image\r\n",
    "from torch.utils.data import Dataset\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class KomatsDataset(Dataset):\r\n",
    "    def __init__(self, img_dir, mask_dir, transform=None):\r\n",
    "        self.img_dir = img_dir\r\n",
    "        self.mask_dir = mask_dir\r\n",
    "        self.transform = transform\r\n",
    "        self.imgs = os.listdir(img_dir)\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.imgs)\r\n",
    "\r\n",
    "    def __getitem__(self, index):\r\n",
    "        img_path = os.path.join(self.img_dir, self.imgs[index])\r\n",
    "        mask_path = os.path.join(self.mask_dir, self.imgs[index].replace(\"rgb\", \"label\"))\r\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\r\n",
    "        mask = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.float32)\r\n",
    "        mask[mask != 0] = 1.0\r\n",
    "\r\n",
    "        if self.transform is not None:\r\n",
    "            augmentation = self.transform(image=image, mask=mask)\r\n",
    "            image = augmentation[\"image\"]\r\n",
    "            mask = augmentation[\"mask\"]\r\n",
    "\r\n",
    "\r\n",
    "        return image, mask"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import albumentations as A\r\n",
    "from albumentations.pytorch import ToTensorV2\r\n",
    "from tqdm import tqdm \r\n",
    "import torch.optim as optim \r\n",
    "# from utils import (load_checkpoint, save_checkpoint, get_loaders, check_accuracy, save_predictions_as_imgs)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyper Parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "LEARNING_RATE = 1E-4\r\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
    "BATCH_SIZE = 32\r\n",
    "NUM_EPOCHS = 10\r\n",
    "NUM_WORKERS = 2\r\n",
    "IMAGE_HEIGHT = 480\r\n",
    "IMAGE_WIDHT = 480\r\n",
    "PIN_MEMORY = True\r\n",
    "LOAD_MODEL = True\r\n",
    "TRAIN_IMG_DIR = \".\\dataset\\multi\\multi_plant\"\r\n",
    "TRAIN_IMG_LABEL = \".\\dataset\\multi\\multi_label\"\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e2381145111bc30c3424d071b9e1a3a4425b595547cfd3fc534ba4a3db9b7a9c"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('tesi': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}